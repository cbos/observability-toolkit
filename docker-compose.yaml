version: '3.8'

services:
  loki:
    image: "${LOKI_IMAGE_NAME:-grafana/loki:3.2.0}"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      start_period: 20s
      interval: 10s
      timeout: 5s
      retries: 5
    command:
      - -config.file=/etc/loki/loki-config.yaml
    volumes:
      - ./config/loki/loki-config.yaml:/etc/loki/loki-config.yaml
      - data-loki:/loki
    restart: unless-stopped

  tempo:
    image: "${TEMPO_IMAGE_NAME:-grafana/tempo:2.6.0}"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3200/ready || exit 1" ]
      start_period: 20s
      interval: 10s
      timeout: 5s
      retries: 5
    command: [ "-config.file=/etc/tempo.yaml" ]
    restart: unless-stopped
    volumes:
      - ./config/tempo/tempo-config.yaml:/etc/tempo.yaml
      - data-tempo:/tmp/tempo

  prometheus:
    image: "${PROMETHEUS_IMAGE_NAME:-prom/prometheus:v2.49.1}"
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy" ]
      start_period: 20s
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - data-prometheus:/prometheus
    command:
      # Standard config
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      # Additional config
      # retention policy is 15 days default. Changed it to 30 days, as more days takes too much storage
      - '--storage.tsdb.retention.time=30d'
      # The maximum number of bytes of storage blocks to retain. The oldest data will be removed first. Defaults to 0 or disabled. Units supported: B, KB, MB, GB, TB, PB, EB. Ex: "512MB". Based on powers-of-2, so 1KB is 1024B. Only the persistent blocks are deleted to honor this retention although WAL and m-mapped chunks are counted in the total size. So the minimum requirement for the disk is the peak space taken by the wal (the WAL and Checkpoint) and chunks_head (m-mapped Head chunks) directory combined (peaks every 2 hours).
      - '--storage.tsdb.retention.size=30GB'
      #  Maximum time a query may take before being aborted.
      - '--query.timeout=1m'
      # https://prometheus.io/docs/prometheus/latest/feature_flags/#remote-write-receiver
      # https://prometheus.io/docs/prometheus/latest/storage/#overview
      - '--web.enable-remote-write-receiver'
      # https://prometheus.io/docs/prometheus/latest/feature_flags/#exemplars-storage
      - '--enable-feature=exemplar-storage'

  grafana:
    image: "${GRAFANA_IMAGE_NAME:-grafana/grafana:11.2.2}"
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:3000" ]
      start_period: 20s
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "${GRAFANA_HOST_PORT:-3000}:3000"
    environment:
      GF_AUTH_ANONYMOUS_ENABLED: true
      GF_AUTH_ANONYMOUS_ORG_ROLE: Admin
      GF_AUTH_ORG_ROLE: Admin
      GF_AUTH_DISABLE_LOGIN_FORM: true
      GF_USERS_VIEWERS_CAN_EDIT: true
      GF_USERS_EDITORS_CAN_ADMIN: true
      GF_INSTALL_PLUGINS: https://storage.googleapis.com/integration-artifacts/grafana-lokiexplore-app/grafana-lokiexplore-app-latest.zip;grafana-lokiexplore-app,pyroscope-panel
      GF_FEATURE_TOGGLES_ENABLE: tempoSearch tempoBackendSearch tempoServiceGraph tempoApmTable traceToMetrics newTraceViewHeader metricsSummary correlations traceToProfiles tracesEmbeddedFlameGraph
    volumes:
      - ./config/grafana/provisioning/:/etc/grafana/provisioning/
      - data-grafana:/var/lib/grafana
    restart: unless-stopped

  opentelemetry-collector:
    image: "${OTEL_COLLECTOR_IMAGE_NAME:-otel/opentelemetry-collector-contrib:0.96.0}"
    command: [ "--config=/etc/otel-collector-config.yaml" ]
    volumes:
      - ./config/opentelemetry-collector/otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "${OTEL_COLLECTOR_HOST_PORT_PROMETHEUS:-8889}:8889"   # Prometheus exporter metrics
      - "${OTEL_COLLECTOR_HOST_PORT_GRPC:-4317}:4317"         # otlp receiver GRPC
      - "${OTEL_COLLECTOR_HOST_PORT_HTTP:-4318}:4318"         # otlp receiver HTTP

  promtail:
    image: "${PROMTAIL_IMAGE_NAME:-grafana/promtail:2.9.5}"
    command: -config.file=/etc/promtail/promtail-config.yaml
    volumes:
      - ./promtail_input:/var/log
      - ./config/promtail/promtail-config.yaml:/etc/promtail/promtail-config.yaml

  pyroscope:
    image: "${PYROSCOPE_IMAGE_NAME:-grafana/pyroscope:1.5.0}"
    environment:
      JAEGER_AGENT_HOST: tempo
      JAEGER_SAMPLER_TYPE: const
      JAEGER_SAMPLER_PARAM: 1
    command: [ "-config.file=/etc/pyroscope.yml" ]
    ports:
      - "${PYROSCOPE_PORT:-4040}:4040"
    volumes:
      - ./config/pyroscope/pyroscope.yml:/etc/pyroscope.yml

volumes:
  data-loki:
  data-tempo:
  data-prometheus:
  data-grafana:
